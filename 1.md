# DnCNN UDnCNN DUDnCNN


## 1. 下载数据集


```python
!wget -N https://raw.githubusercontent.com/eebowen/Transfer-Learning-and-Deep-Neural-Network-Acceleration-for-Image-Classification/master/nntools.py
!wget -N https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/bsds/BSDS300-images.tgz
!tar -zxvf BSDS300-images.tgz
dataset_root_dir = './BSDS300/images/'
```

    --2021-06-17 15:11:46--  https://raw.githubusercontent.com/eebowen/Transfer-Learning-and-Deep-Neural-Network-Acceleration-for-Image-Classification/master/nntools.py
    Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...
    Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.
    HTTP request sent, awaiting response... 200 OK
    Length: 12781 (12K) [text/plain]
    Saving to: ‘nntools.py’
    
    nntools.py          100%[===================>]  12.48K  --.-KB/s    in 0s      
    
    Last-modified header missing -- time-stamps turned off.
    2021-06-17 15:11:46 (51.1 MB/s) - ‘nntools.py’ saved [12781/12781]
    
    --2021-06-17 15:11:46--  https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/bsds/BSDS300-images.tgz
    Resolving www2.eecs.berkeley.edu (www2.eecs.berkeley.edu)... 128.32.244.190
    Connecting to www2.eecs.berkeley.edu (www2.eecs.berkeley.edu)|128.32.244.190|:443... connected.
    HTTP request sent, awaiting response... 200 OK
    Length: 22211847 (21M) [application/x-tar]
    Saving to: ‘BSDS300-images.tgz’
    
    BSDS300-images.tgz  100%[===================>]  21.18M  3.31MB/s    in 5.6s    
    
    2021-06-17 15:11:53 (3.76 MB/s) - ‘BSDS300-images.tgz’ saved [22211847/22211847]
    
    BSDS300/images/
    BSDS300/images/train/
    BSDS300/images/train/159029.jpg
    BSDS300/images/train/20008.jpg
    BSDS300/images/train/155060.jpg
    BSDS300/images/train/286092.jpg
    BSDS300/images/train/100075.jpg
    BSDS300/images/train/61060.jpg
    BSDS300/images/train/46076.jpg
    BSDS300/images/train/301007.jpg
    BSDS300/images/train/26031.jpg
    BSDS300/images/train/232038.jpg
    BSDS300/images/train/45077.jpg
    BSDS300/images/train/365025.jpg
    BSDS300/images/train/188091.jpg
    BSDS300/images/train/299091.jpg
    BSDS300/images/train/181079.jpg
    BSDS300/images/train/22090.jpg
    BSDS300/images/train/370036.jpg
    BSDS300/images/train/15088.jpg
    BSDS300/images/train/22093.jpg
    BSDS300/images/train/376020.jpg
    BSDS300/images/train/187071.jpg
    BSDS300/images/train/105053.jpg
    BSDS300/images/train/271008.jpg
    BSDS300/images/train/277095.jpg
    BSDS300/images/train/198023.jpg
    BSDS300/images/train/65074.jpg
    BSDS300/images/train/189003.jpg
    BSDS300/images/train/187029.jpg
    BSDS300/images/train/103041.jpg
    BSDS300/images/train/163014.jpg
    BSDS300/images/train/56028.jpg
    BSDS300/images/train/55075.jpg
    BSDS300/images/train/41004.jpg
    BSDS300/images/train/198054.jpg
    BSDS300/images/train/28096.jpg
    BSDS300/images/train/12003.jpg
    BSDS300/images/train/187039.jpg
    BSDS300/images/train/76002.jpg
    BSDS300/images/train/42044.jpg
    BSDS300/images/train/122048.jpg
    BSDS300/images/train/145053.jpg
    BSDS300/images/train/68077.jpg
    BSDS300/images/train/361084.jpg
    BSDS300/images/train/43083.jpg
    BSDS300/images/train/236017.jpg
    BSDS300/images/train/35058.jpg
    BSDS300/images/train/66075.jpg
    BSDS300/images/train/374020.jpg
    BSDS300/images/train/94079.jpg
    BSDS300/images/train/138078.jpg
    BSDS300/images/train/292066.jpg
    BSDS300/images/train/130034.jpg
    BSDS300/images/train/59078.jpg
    BSDS300/images/train/170054.jpg
    BSDS300/images/train/385028.jpg
    BSDS300/images/train/67079.jpg
    BSDS300/images/train/365073.jpg
    BSDS300/images/train/33066.jpg
    BSDS300/images/train/166081.jpg
    BSDS300/images/train/113009.jpg
    BSDS300/images/train/227046.jpg
    BSDS300/images/train/35091.jpg
    BSDS300/images/train/309004.jpg
    BSDS300/images/train/65132.jpg
    BSDS300/images/train/372047.jpg
    BSDS300/images/train/176039.jpg
    BSDS300/images/train/285036.jpg
    BSDS300/images/train/253036.jpg
    BSDS300/images/train/274007.jpg
    BSDS300/images/train/109034.jpg
    BSDS300/images/train/108073.jpg
    BSDS300/images/train/157036.jpg
    BSDS300/images/train/100098.jpg
    BSDS300/images/train/35008.jpg
    BSDS300/images/train/92059.jpg
    BSDS300/images/train/245051.jpg
    BSDS300/images/train/209070.jpg
    BSDS300/images/train/27059.jpg
    BSDS300/images/train/176019.jpg
    BSDS300/images/train/54005.jpg
    BSDS300/images/train/249087.jpg
    BSDS300/images/train/249061.jpg
    BSDS300/images/train/317080.jpg
    BSDS300/images/train/172032.jpg
    BSDS300/images/train/147062.jpg
    BSDS300/images/train/163062.jpg
    BSDS300/images/train/140075.jpg
    BSDS300/images/train/260081.jpg
    BSDS300/images/train/353013.jpg
    BSDS300/images/train/374067.jpg
    BSDS300/images/train/164074.jpg
    BSDS300/images/train/104022.jpg
    BSDS300/images/train/135037.jpg
    BSDS300/images/train/42078.jpg
    BSDS300/images/train/134052.jpg
    BSDS300/images/train/268002.jpg
    BSDS300/images/train/16052.jpg
    BSDS300/images/train/247085.jpg
    BSDS300/images/train/302003.jpg
    BSDS300/images/train/227040.jpg
    BSDS300/images/train/246053.jpg
    BSDS300/images/train/2092.jpg
    BSDS300/images/train/183055.jpg
    BSDS300/images/train/239096.jpg
    BSDS300/images/train/216053.jpg
    BSDS300/images/train/55067.jpg
    BSDS300/images/train/71046.jpg
    BSDS300/images/train/113044.jpg
    BSDS300/images/train/207056.jpg
    BSDS300/images/train/310007.jpg
    BSDS300/images/train/169012.jpg
    BSDS300/images/train/216041.jpg
    BSDS300/images/train/198004.jpg
    BSDS300/images/train/181091.jpg
    BSDS300/images/train/181018.jpg
    BSDS300/images/train/28075.jpg
    BSDS300/images/train/41025.jpg
    BSDS300/images/train/65019.jpg
    BSDS300/images/train/80099.jpg
    BSDS300/images/train/97017.jpg
    BSDS300/images/train/65010.jpg
    BSDS300/images/train/323016.jpg
    BSDS300/images/train/311068.jpg
    BSDS300/images/train/78019.jpg
    BSDS300/images/train/135069.jpg
    BSDS300/images/train/231015.jpg
    BSDS300/images/train/23084.jpg
    BSDS300/images/train/147021.jpg
    BSDS300/images/train/159091.jpg
    BSDS300/images/train/25098.jpg
    BSDS300/images/train/8143.jpg
    BSDS300/images/train/24004.jpg
    BSDS300/images/train/23025.jpg
    BSDS300/images/train/188005.jpg
    BSDS300/images/train/145014.jpg
    BSDS300/images/train/189011.jpg
    BSDS300/images/train/48055.jpg
    BSDS300/images/train/35010.jpg
    BSDS300/images/train/15004.jpg
    BSDS300/images/train/100080.jpg
    BSDS300/images/train/161062.jpg
    BSDS300/images/train/126039.jpg
    BSDS300/images/train/254054.jpg
    BSDS300/images/train/239007.jpg
    BSDS300/images/train/118035.jpg
    BSDS300/images/train/113016.jpg
    BSDS300/images/train/238011.jpg
    BSDS300/images/train/61086.jpg
    BSDS300/images/train/151087.jpg
    BSDS300/images/train/106025.jpg
    BSDS300/images/train/159045.jpg
    BSDS300/images/train/43070.jpg
    BSDS300/images/train/112082.jpg
    BSDS300/images/train/105019.jpg
    BSDS300/images/train/368078.jpg
    BSDS300/images/train/117054.jpg
    BSDS300/images/train/134008.jpg
    BSDS300/images/train/35070.jpg
    BSDS300/images/train/388016.jpg
    BSDS300/images/train/24063.jpg
    BSDS300/images/train/140055.jpg
    BSDS300/images/train/178054.jpg
    BSDS300/images/train/90076.jpg
    BSDS300/images/train/106020.jpg
    BSDS300/images/train/368016.jpg
    BSDS300/images/train/144067.jpg
    BSDS300/images/train/216066.jpg
    BSDS300/images/train/153093.jpg
    BSDS300/images/train/293029.jpg
    BSDS300/images/train/311081.jpg
    BSDS300/images/train/124084.jpg
    BSDS300/images/train/246016.jpg
    BSDS300/images/train/156079.jpg
    BSDS300/images/train/254033.jpg
    BSDS300/images/train/95006.jpg
    BSDS300/images/train/60079.jpg
    BSDS300/images/train/225017.jpg
    BSDS300/images/train/188063.jpg
    BSDS300/images/train/326038.jpg
    BSDS300/images/train/118020.jpg
    BSDS300/images/train/12074.jpg
    BSDS300/images/train/173036.jpg
    BSDS300/images/train/187083.jpg
    BSDS300/images/train/176035.jpg
    BSDS300/images/train/187003.jpg
    BSDS300/images/train/66039.jpg
    BSDS300/images/train/153077.jpg
    BSDS300/images/train/271031.jpg
    BSDS300/images/train/23080.jpg
    BSDS300/images/train/202012.jpg
    BSDS300/images/train/196015.jpg
    BSDS300/images/train/108041.jpg
    BSDS300/images/train/376001.jpg
    BSDS300/images/train/242078.jpg
    BSDS300/images/train/138032.jpg
    BSDS300/images/train/8049.jpg
    BSDS300/images/train/314016.jpg
    BSDS300/images/train/22013.jpg
    BSDS300/images/train/87065.jpg
    BSDS300/images/train/183087.jpg
    BSDS300/images/test/
    BSDS300/images/test/119082.jpg
    BSDS300/images/test/170057.jpg
    BSDS300/images/test/58060.jpg
    BSDS300/images/test/163085.jpg
    BSDS300/images/test/42049.jpg
    BSDS300/images/test/167062.jpg
    BSDS300/images/test/157055.jpg
    BSDS300/images/test/295087.jpg
    BSDS300/images/test/24077.jpg
    BSDS300/images/test/78004.jpg
    BSDS300/images/test/220075.jpg
    BSDS300/images/test/45096.jpg
    BSDS300/images/test/38092.jpg
    BSDS300/images/test/43074.jpg
    BSDS300/images/test/16077.jpg
    BSDS300/images/test/86000.jpg
    BSDS300/images/test/101085.jpg
    BSDS300/images/test/219090.jpg
    BSDS300/images/test/89072.jpg
    BSDS300/images/test/300091.jpg
    BSDS300/images/test/126007.jpg
    BSDS300/images/test/156065.jpg
    BSDS300/images/test/76053.jpg
    BSDS300/images/test/296007.jpg
    BSDS300/images/test/175032.jpg
    BSDS300/images/test/253027.jpg
    BSDS300/images/test/304034.jpg
    BSDS300/images/test/86016.jpg
    BSDS300/images/test/103070.jpg
    BSDS300/images/test/8023.jpg
    BSDS300/images/test/260058.jpg
    BSDS300/images/test/41033.jpg
    BSDS300/images/test/291000.jpg
    BSDS300/images/test/109053.jpg
    BSDS300/images/test/130026.jpg
    BSDS300/images/test/241004.jpg
    BSDS300/images/test/108082.jpg
    BSDS300/images/test/285079.jpg
    BSDS300/images/test/147091.jpg
    BSDS300/images/test/69040.jpg
    BSDS300/images/test/14037.jpg
    BSDS300/images/test/54082.jpg
    BSDS300/images/test/189080.jpg
    BSDS300/images/test/229036.jpg
    BSDS300/images/test/62096.jpg
    BSDS300/images/test/271035.jpg
    BSDS300/images/test/167083.jpg
    BSDS300/images/test/12084.jpg
    BSDS300/images/test/69015.jpg
    BSDS300/images/test/148089.jpg
    BSDS300/images/test/160068.jpg
    BSDS300/images/test/145086.jpg
    BSDS300/images/test/216081.jpg
    BSDS300/images/test/97033.jpg
    BSDS300/images/test/182053.jpg
    BSDS300/images/test/208001.jpg
    BSDS300/images/test/19021.jpg
    BSDS300/images/test/227092.jpg
    BSDS300/images/test/134035.jpg
    BSDS300/images/test/223061.jpg
    BSDS300/images/test/253055.jpg
    BSDS300/images/test/148026.jpg
    BSDS300/images/test/210088.jpg
    BSDS300/images/test/86068.jpg
    BSDS300/images/test/3096.jpg
    BSDS300/images/test/41069.jpg
    BSDS300/images/test/21077.jpg
    BSDS300/images/test/196073.jpg
    BSDS300/images/test/108070.jpg
    BSDS300/images/test/123074.jpg
    BSDS300/images/test/376043.jpg
    BSDS300/images/test/306005.jpg
    BSDS300/images/test/38082.jpg
    BSDS300/images/test/33039.jpg
    BSDS300/images/test/108005.jpg
    BSDS300/images/test/106024.jpg
    BSDS300/images/test/302008.jpg
    BSDS300/images/test/102061.jpg
    BSDS300/images/test/197017.jpg
    BSDS300/images/test/299086.jpg
    BSDS300/images/test/37073.jpg
    BSDS300/images/test/241048.jpg
    BSDS300/images/test/65033.jpg
    BSDS300/images/test/55073.jpg
    BSDS300/images/test/66053.jpg
    BSDS300/images/test/143090.jpg
    BSDS300/images/test/85048.jpg
    BSDS300/images/test/42012.jpg
    BSDS300/images/test/351093.jpg
    BSDS300/images/test/361010.jpg
    BSDS300/images/test/175043.jpg
    BSDS300/images/test/87046.jpg
    BSDS300/images/test/105025.jpg
    BSDS300/images/test/236037.jpg
    BSDS300/images/test/101087.jpg
    BSDS300/images/test/304074.jpg
    BSDS300/images/test/296059.jpg
    BSDS300/images/test/159008.jpg
    BSDS300/images/test/385039.jpg
    BSDS300/images/test/69020.jpg
    BSDS300/iids_test.txt
    BSDS300/iids_train.txt
    


```python
%matplotlib inline

import os
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.utils.data as td
import torchvision as tv
from PIL import Image
import matplotlib.pyplot as plt
import nntools as nt
import time
```


```python
device = 'cuda:0' if torch.cuda.is_available() else 'cpu'
print(device)
```

    cuda:0
    

## 2. 训练集加噪

$σ = 30$ 高斯噪音 $180 × 180$ 裁剪（左上角或随机位置）


```python
class NoisyBSDSDataset(td.Dataset):

    def __init__(self, root_dir, mode='train', image_size=(180, 180), sigma=30):
        super(NoisyBSDSDataset, self).__init__()
        self.mode = mode
        self.image_size = image_size
        self.sigma = sigma
        self.images_dir = os.path.join(root_dir, mode)
        self.files = os.listdir(self.images_dir)

    def __len__(self):
        return len(self.files)

    def __repr__(self):
        return "NoisyBSDSDataset(mode={}, image_size={}, sigma={})". \
            format(self.mode, self.image_size, self.sigma)

    def __getitem__(self, idx):
        img_path = os.path.join(self.images_dir, self.files[idx])
        clean = Image.open(img_path).convert('RGB')   
        # 随机裁剪
        #i = np.random.randint(clean.size[0] - self.image_size[0])
        #j = np.random.randint(clean.size[1] - self.image_size[1])
        i=0
        j=0
        clean = clean.crop([i, j, i+self.image_size[0], j+self.image_size[1]])
        transform = tv.transforms.Compose([
            # 转换张量
            tv.transforms.ToTensor(),
            # [−1, 1]
            tv.transforms.Normalize((.5, .5, .5), (.5, .5, .5))
            ])
        clean = transform(clean)
        
        noisy = clean + 2 / 255 * self.sigma * torch.randn(clean.shape)
        return noisy, clean
```


```python
def myimshow(image, ax=plt):
    image = image.to('cpu').numpy()
    image = np.moveaxis(image, [0, 1, 2], [2, 0, 1])
    image = (image + 1) / 2
    image[image < 0] = 0
    image[image > 1] = 1
    h = ax.imshow(image)
    ax.axis('off')
    return h
```

#### 导训练集和测试集进来


```python
train_set = NoisyBSDSDataset(dataset_root_dir)
test_set = NoisyBSDSDataset(dataset_root_dir, mode='test', image_size=(320, 320))
```


```python
x = test_set[0]
fig, axes = plt.subplots(ncols=2)
myimshow(x[0], ax=axes[0])
axes[0].set_title('Noisy')
myimshow(x[1], ax=axes[1])
axes[1].set_title('Clean')
print(f'image size is {x[0].shape}.')
```

    image size is torch.Size([3, 320, 320]).
    


    
![png](1_files/1_11_1.png)
    


## 3. DnCNN

#### loss 用的均方差


```python
class NNRegressor(nt.NeuralNetwork):

    def __init__(self):
        super(NNRegressor, self).__init__()
        self.mse = nn.MSELoss()

    def criterion(self, y, d):
        return self.mse(y, d)
```

### CNN 网络为啥要带个权重

看这个台湾人写的比较清楚
[深度學習: Weight initialization和Batch Normalization](https://chih-sheng-huang821.medium.com/%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92-weight-initialization%E5%92%8Cbatch-normalization-f264c4be37f5)

#### 无权初始化


```python
class DnCNN(NNRegressor):

    def __init__(self, D, C=64):
        super(DnCNN, self).__init__()
        self.D = D
        
        self.conv = nn.ModuleList()
        self.conv.append(nn.Conv2d(3, C, 3, padding=1))
        self.conv.extend([nn.Conv2d(C, C, 3, padding=1) for _ in range(D)])
        self.conv.append(nn.Conv2d(C, 3, 3, padding=1))
        
        self.bn = nn.ModuleList()
        for k in range(D):
            self.bn.append(nn.BatchNorm2d(C, C))

    def forward(self, x):
        D = self.D
        h = F.relu(self.conv[0](x))
        for i in range(D):
            h = F.relu(self.bn[i](self.conv[i+1](h)))
        y = self.conv[D+1](h) + x
        return y
```

零填充（泛卷积）对输入图像矩阵的边缘进行滤波，是玄学


```python
x, _ = train_set[-1]
x = x.unsqueeze(0).to(device)
Ds = [0, 1, 2, 4, 8]

fig, axes = plt.subplots(nrows=len(Ds), ncols=3, figsize=(9,9))
for i in range(len(Ds)):
    with torch.no_grad():
        model = DnCNN(Ds[i]).to(device)
        y = model.forward(x) # 4-d
    # 3-d
    myimshow(x[0], ax=axes[i][0])
    axes[i][0].set_title('x[0]')
    myimshow(y[0], ax=axes[i][1])
    axes[i][1].set_title(f'y[0] (D={Ds[i]})')
    myimshow(x[0]-y[0], ax=axes[i][2])
    axes[i][2].set_title(f'x[0]-y[0] (D={Ds[i]})')
```


    
![png](1_files/1_19_0.png)
    


D=0 才有残差输出，梯度消失，没法炼丹

#### 带权跑一下


```python
class DnCNN(NNRegressor):

    def __init__(self, D, C=64):
        super(DnCNN, self).__init__()
        self.D = D
        
        self.conv = nn.ModuleList()
        self.conv.append(nn.Conv2d(3, C, 3, padding=1))
        self.conv.extend([nn.Conv2d(C, C, 3, padding=1) for _ in range(D)])
        self.conv.append(nn.Conv2d(C, 3, 3, padding=1))
        # Kaiming正态分布初始化，又叫啥He('s) initialization
        for i in range(len(self.conv[:-1])):
            nn.init.kaiming_normal_(self.conv[i].weight.data, nonlinearity='relu')
        
        # Batch norm
        self.bn = nn.ModuleList()
        self.bn.extend([nn.BatchNorm2d(C, C) for _ in range(D)])
        # Batch norm layer 初始化权值
        for i in range(D):
            nn.init.constant_(self.bn[i].weight.data, 1.25 * np.sqrt(C))

    def forward(self, x):
        D = self.D
        h = F.relu(self.conv[0](x))
        for i in range(D):
            h = F.relu(self.bn[i](self.conv[i+1](h)))
        y = self.conv[D+1](h) + x
        return y
```


```python
x, _ = train_set[-1]
x = x.unsqueeze(0).to(device)
Ds = [0, 1, 2, 4, 8]

fig, axes = plt.subplots(nrows=len(Ds), ncols=3, figsize=(9,9))
for i in range(len(Ds)):
    with torch.no_grad():
        model = DnCNN(Ds[i]).to(device)
        y = model.forward(x)
    
    myimshow(x[0], ax=axes[i][0])
    axes[i][0].set_title('x[0]')
    myimshow(y[0], ax=axes[i][1])
    axes[i][1].set_title(f'y[0] (D={Ds[i]})')
    myimshow(x[0]-y[0], ax=axes[i][2])
    axes[i][2].set_title(f'x[0]-y[0] (D={Ds[i]})')
```


    
![png](1_files/1_23_0.png)
    


然后残差就非零，能梯度下降，能炼丹

### PSNR

峰值信噪比 PSNR (Peak Signal-to-Noise-Ratio)，值域是 `[−1, 1]` 
$$
PSNR = 10\log_{10}\frac{4n}{\Vert y-d\Vert_2^2}
$$

`d` 是理想值， `y` 是估计值，分母就是均方差， `n` 是张量大小，对数定义，单位是 `dB`，数越大越好

#### 这东西是要算平均的


```python
class DenoisingStatsManager(nt.StatsManager):

    def __init__(self):
        super(DenoisingStatsManager, self).__init__()

    def init(self):
        super(DenoisingStatsManager, self).init()
        self.running_psnr = 0

    def accumulate(self, loss, x, y, d):
        super(DenoisingStatsManager, self).accumulate(loss, x, y, d)    
        n = x.shape[0] * x.shape[1] * x.shape[2] * x.shape[3]
        self.running_psnr += 10*torch.log10(4*n/(torch.norm(y-d)**2))

    def summarize(self):
        loss = super(DenoisingStatsManager, self).summarize()
        psnr = self.running_psnr / self.number_update
        return {'loss': loss, 'PSNR': psnr.cpu()}
```


```python
def plot(exp, fig, axes, noisy, visu_rate=2):
    if exp.epoch % visu_rate != 0:
        return
    with torch.no_grad():
        denoised = exp.net(noisy[None].to(net.device))[0]
    axes[0][0].clear()
    axes[0][1].clear()
    axes[1][0].clear()
    axes[1][1].clear()
    myimshow(noisy, ax=axes[0][0])
    axes[0][0].set_title('Noisy image')
    
    myimshow(denoised, ax=axes[0][1])
    axes[0][1].set_title('Denoised image')
    
    axes[1][0].plot([exp.history[k][0]['loss'] for k in range(exp.epoch)], label='training loss')
    axes[1][0].set_ylabel('Loss')
    axes[1][0].set_xlabel('Epoch')
    axes[1][0].legend()
    
    axes[1][1].plot([exp.history[k][0]['PSNR'] for k in range(exp.epoch)], label='training psnr')
    axes[1][1].set_ylabel('PSNR')
    axes[1][1].set_xlabel('Epoch')
    axes[1][1].legend()
    
    plt.tight_layout()
    fig.canvas.draw()
```

### `DnCNN` 炼丹


```python
lr = 1e-3
net = DnCNN(6).to(device)
adam = torch.optim.Adam(net.parameters(), lr=lr)
stats_manager = DenoisingStatsManager()
exp1 = nt.Experiment(net, train_set, test_set, adam, stats_manager, batch_size=4, 
               output_dir="./checkpoints/denoising1", perform_validation_during_training=True)
```


```python
fig, axes = plt.subplots(ncols=2, nrows=2, figsize=(9, 7))
exp1.run(num_epochs=200, plot=lambda exp: plot(exp, fig=fig, axes=axes,
                                                noisy=test_set[0][0]))
```

    Start/Continue training from epoch 0
    Epoch 1 (Time: 18.20s)
    Epoch 2 (Time: 18.09s)
    Epoch 3 (Time: 17.89s)
    Epoch 4 (Time: 17.89s)
    Epoch 5 (Time: 17.88s)
    Epoch 6 (Time: 17.84s)
    Epoch 7 (Time: 17.83s)
    Epoch 8 (Time: 17.88s)
    Epoch 9 (Time: 17.84s)
    Epoch 10 (Time: 17.81s)
    Epoch 11 (Time: 17.92s)
    Epoch 12 (Time: 17.87s)
    Epoch 13 (Time: 17.91s)
    Epoch 14 (Time: 17.89s)
    Epoch 15 (Time: 17.82s)
    Epoch 16 (Time: 17.83s)
    Epoch 17 (Time: 17.86s)
    Epoch 18 (Time: 17.82s)
    Epoch 19 (Time: 17.82s)
    Epoch 20 (Time: 17.88s)
    Epoch 21 (Time: 17.89s)
    Epoch 22 (Time: 17.88s)
    Epoch 23 (Time: 17.84s)
    Epoch 24 (Time: 17.85s)
    Epoch 25 (Time: 17.83s)
    Epoch 26 (Time: 17.90s)
    Epoch 27 (Time: 17.76s)
    Epoch 28 (Time: 17.90s)
    Epoch 29 (Time: 17.89s)
    Epoch 30 (Time: 17.90s)
    Epoch 31 (Time: 17.87s)
    Epoch 32 (Time: 17.90s)
    Epoch 33 (Time: 17.85s)
    Epoch 34 (Time: 17.89s)
    Epoch 35 (Time: 17.84s)
    Epoch 36 (Time: 17.85s)
    Epoch 37 (Time: 17.86s)
    Epoch 38 (Time: 17.88s)
    Epoch 39 (Time: 17.83s)
    Epoch 40 (Time: 17.77s)
    Epoch 41 (Time: 17.77s)
    Epoch 42 (Time: 17.74s)
    Epoch 43 (Time: 17.80s)
    Epoch 44 (Time: 17.87s)
    Epoch 45 (Time: 17.84s)
    Epoch 46 (Time: 17.82s)
    Epoch 47 (Time: 17.78s)
    Epoch 48 (Time: 17.79s)
    Epoch 49 (Time: 17.81s)
    Epoch 50 (Time: 17.80s)
    Epoch 51 (Time: 17.78s)
    Epoch 52 (Time: 17.78s)
    Epoch 53 (Time: 17.81s)
    Epoch 54 (Time: 17.79s)
    Epoch 55 (Time: 17.81s)
    Epoch 56 (Time: 17.77s)
    Epoch 57 (Time: 17.76s)
    Epoch 58 (Time: 17.78s)
    Epoch 59 (Time: 17.77s)
    Epoch 60 (Time: 17.77s)
    Epoch 61 (Time: 17.80s)
    Epoch 62 (Time: 17.80s)
    Epoch 63 (Time: 17.78s)
    Epoch 64 (Time: 17.80s)
    Epoch 65 (Time: 17.81s)
    Epoch 66 (Time: 17.69s)
    Epoch 67 (Time: 17.78s)
    Epoch 68 (Time: 17.76s)
    Epoch 69 (Time: 17.78s)
    Epoch 70 (Time: 17.79s)
    Epoch 71 (Time: 17.75s)
    Epoch 72 (Time: 17.81s)
    Epoch 73 (Time: 17.83s)
    Epoch 74 (Time: 17.81s)
    Epoch 75 (Time: 17.81s)
    Epoch 76 (Time: 17.85s)
    Epoch 77 (Time: 17.84s)
    Epoch 78 (Time: 17.85s)
    Epoch 79 (Time: 17.83s)
    Epoch 80 (Time: 17.84s)
    Epoch 81 (Time: 17.80s)
    Epoch 82 (Time: 17.86s)
    Epoch 83 (Time: 17.82s)
    Epoch 84 (Time: 17.84s)
    Epoch 85 (Time: 17.78s)
    Epoch 86 (Time: 17.88s)
    Epoch 87 (Time: 17.85s)
    Epoch 88 (Time: 17.84s)
    Epoch 89 (Time: 17.84s)
    Epoch 90 (Time: 17.73s)
    Epoch 91 (Time: 17.86s)
    Epoch 92 (Time: 17.85s)
    Epoch 93 (Time: 17.83s)
    Epoch 94 (Time: 17.80s)
    Epoch 95 (Time: 17.78s)
    Epoch 96 (Time: 17.84s)
    Epoch 97 (Time: 17.80s)
    Epoch 98 (Time: 17.82s)
    Epoch 99 (Time: 17.81s)
    Epoch 100 (Time: 17.82s)
    Epoch 101 (Time: 17.83s)
    Epoch 102 (Time: 17.82s)
    Epoch 103 (Time: 17.80s)
    Epoch 104 (Time: 17.82s)
    Epoch 105 (Time: 17.79s)
    Epoch 106 (Time: 17.83s)
    Epoch 107 (Time: 17.79s)
    Epoch 108 (Time: 17.81s)
    Epoch 109 (Time: 17.83s)
    Epoch 110 (Time: 17.83s)
    Epoch 111 (Time: 17.79s)
    Epoch 112 (Time: 17.80s)
    Epoch 113 (Time: 17.83s)
    Epoch 114 (Time: 17.82s)
    Epoch 115 (Time: 17.80s)
    Epoch 116 (Time: 17.80s)
    Epoch 117 (Time: 17.81s)
    Epoch 118 (Time: 17.82s)
    Epoch 119 (Time: 17.79s)
    Epoch 120 (Time: 17.80s)
    Epoch 121 (Time: 17.85s)
    Epoch 122 (Time: 17.81s)
    Epoch 123 (Time: 17.79s)
    Epoch 124 (Time: 17.79s)
    Epoch 125 (Time: 17.84s)
    Epoch 126 (Time: 17.82s)
    Epoch 127 (Time: 17.78s)
    Epoch 128 (Time: 17.85s)
    Epoch 129 (Time: 17.79s)
    Epoch 130 (Time: 17.78s)
    Epoch 131 (Time: 17.81s)
    Epoch 132 (Time: 17.83s)
    Epoch 133 (Time: 17.81s)
    Epoch 134 (Time: 17.80s)
    Epoch 135 (Time: 17.82s)
    Epoch 136 (Time: 17.82s)
    Epoch 137 (Time: 17.78s)
    Epoch 138 (Time: 17.84s)
    Epoch 139 (Time: 17.82s)
    Epoch 140 (Time: 17.84s)
    Epoch 141 (Time: 17.79s)
    Epoch 142 (Time: 17.84s)
    Epoch 143 (Time: 17.78s)
    Epoch 144 (Time: 17.86s)
    Epoch 145 (Time: 17.82s)
    Epoch 146 (Time: 17.79s)
    Epoch 147 (Time: 17.77s)
    Epoch 148 (Time: 17.83s)
    Epoch 149 (Time: 17.83s)
    Epoch 150 (Time: 17.86s)
    Epoch 151 (Time: 17.80s)
    Epoch 152 (Time: 17.83s)
    Epoch 153 (Time: 17.80s)
    Epoch 154 (Time: 17.84s)
    Epoch 155 (Time: 17.85s)
    Epoch 156 (Time: 17.78s)
    Epoch 157 (Time: 17.80s)
    Epoch 158 (Time: 17.84s)
    Epoch 159 (Time: 17.80s)
    Epoch 160 (Time: 17.78s)
    Epoch 161 (Time: 17.75s)
    Epoch 162 (Time: 17.80s)
    Epoch 163 (Time: 17.76s)
    Epoch 164 (Time: 17.79s)
    Epoch 165 (Time: 17.80s)
    Epoch 166 (Time: 17.85s)
    Epoch 167 (Time: 17.76s)
    Epoch 168 (Time: 17.81s)
    Epoch 169 (Time: 17.79s)
    Epoch 170 (Time: 17.83s)
    Epoch 171 (Time: 17.76s)
    Epoch 172 (Time: 17.81s)
    Epoch 173 (Time: 17.81s)
    Epoch 174 (Time: 17.79s)
    Epoch 175 (Time: 17.79s)
    Epoch 176 (Time: 17.84s)
    Epoch 177 (Time: 17.77s)
    Epoch 178 (Time: 17.78s)
    Epoch 179 (Time: 17.77s)
    Epoch 180 (Time: 17.83s)
    Epoch 181 (Time: 17.77s)
    Epoch 182 (Time: 17.78s)
    Epoch 183 (Time: 17.77s)
    Epoch 184 (Time: 17.77s)
    Epoch 185 (Time: 17.71s)
    Epoch 186 (Time: 17.80s)
    Epoch 187 (Time: 17.81s)
    Epoch 188 (Time: 17.83s)
    Epoch 189 (Time: 17.82s)
    Epoch 190 (Time: 17.79s)
    Epoch 191 (Time: 17.82s)
    Epoch 192 (Time: 17.82s)
    Epoch 193 (Time: 17.82s)
    Epoch 194 (Time: 17.79s)
    Epoch 195 (Time: 17.78s)
    Epoch 196 (Time: 17.86s)
    Epoch 197 (Time: 17.79s)
    Epoch 198 (Time: 17.79s)
    Epoch 199 (Time: 17.82s)
    Epoch 200 (Time: 17.84s)
    Finish training for 200 epochs
    


    
![png](1_files/1_31_1.png)
    


### 效果


```python
img = []
model = exp1.net.to(device)
titles = ['clean', 'noise', 'DnCNN']

x, clean = test_set[0]
x = x.unsqueeze(0).to(device)
img.append(clean)
img.append(x[0])

model.eval()
with torch.no_grad():
    y = model.forward(x)
img.append(y[0])
    
fig, axes = plt.subplots(ncols=3, figsize=(20,10), sharex='all', sharey='all')
for i in range(len(img)):
    myimshow(img[i], ax=axes[i])
    axes[i].set_title(f'{titles[i]}')
```


    
![png](1_files/1_33_0.png)
    


仍存在噪点，有信息缺失

### `DnCNN` 网络参数


```python
for name, param in model.named_parameters():
    print(name, param.size(), param.requires_grad)
```

    conv.0.weight torch.Size([64, 3, 3, 3]) True
    conv.0.bias torch.Size([64]) True
    conv.1.weight torch.Size([64, 64, 3, 3]) True
    conv.1.bias torch.Size([64]) True
    conv.2.weight torch.Size([64, 64, 3, 3]) True
    conv.2.bias torch.Size([64]) True
    conv.3.weight torch.Size([64, 64, 3, 3]) True
    conv.3.bias torch.Size([64]) True
    conv.4.weight torch.Size([64, 64, 3, 3]) True
    conv.4.bias torch.Size([64]) True
    conv.5.weight torch.Size([64, 64, 3, 3]) True
    conv.5.bias torch.Size([64]) True
    conv.6.weight torch.Size([64, 64, 3, 3]) True
    conv.6.bias torch.Size([64]) True
    conv.7.weight torch.Size([3, 64, 3, 3]) True
    conv.7.bias torch.Size([3]) True
    bn.0.weight torch.Size([64]) True
    bn.0.bias torch.Size([64]) True
    bn.1.weight torch.Size([64]) True
    bn.1.bias torch.Size([64]) True
    bn.2.weight torch.Size([64]) True
    bn.2.bias torch.Size([64]) True
    bn.3.weight torch.Size([64]) True
    bn.3.bias torch.Size([64]) True
    bn.4.weight torch.Size([64]) True
    bn.4.bias torch.Size([64]) True
    bn.5.weight torch.Size([64]) True
    bn.5.bias torch.Size([64]) True
    

参数个数

第一层有 `64 x 3 x 3 x 3` 个 parameter. `D` 层则有 `64 x 64 x 3 x 3 x D`. 最后一层是 `3 x 64 x 3 x 3` . 总共 `3456 + 36864 x D`

感受野 (Receptive Field) 计算：

没有池化层，每层固定增加 $2^{0-0+1}=2$，初始输入层是 1 ，小学奥数得到 $R_D=(1+2\times (D+2))^2$. 

`D=6` 为例， $R_6=17^2$.

据说（待考证）σ = 30 高斯噪声下的降噪，单个像素应受到 33 × 33 个像素影响，据此来确定深度。

感受野 $R_D=(1+2\times (D+2)) \times (1+2\times (D+2))$， 令等于33 得到 $D=14$，参数个数 $3456 + 36864 \times 14 = 519552$。

## 4. UDnCNN
U-net like CNNs


```python
class UDnCNN(NNRegressor):

    def __init__(self, D, C=64):
        super(UDnCNN, self).__init__()
        self.D = D
        
        self.conv = nn.ModuleList()
        self.conv.append(nn.Conv2d(3, C, 3, padding=1))
        self.conv.extend([nn.Conv2d(C, C, 3, padding=1) for _ in range(D)])
        self.conv.append(nn.Conv2d(C, 3, 3, padding=1))
        # Kaiming正态分布初始化，又叫啥He('s) initialization
        for i in range(len(self.conv[:-1])):
            nn.init.kaiming_normal_(self.conv[i].weight.data, nonlinearity='relu')
        
        # batch norm
        self.bn = nn.ModuleList()
        self.bn.extend([nn.BatchNorm2d(C, C) for _ in range(D)])
        # Batch norm layer 初始化权值
        for i in range(D):
            nn.init.constant_(self.bn[i].weight.data, 1.25 * np.sqrt(C))
    # 前面都一样，这里搞个U-Net
    def forward(self, x):
        D = self.D
        h = F.relu(self.conv[0](x))
        h_buff = []
        idx_buff = []
        shape_buff = []
        for i in range(D//2-1):
            shape_buff.append(h.shape)
            h, idx = F.max_pool2d(F.relu(self.bn[i](self.conv[i+1](h))), 
                                  kernel_size=(2,2), return_indices=True)
            h_buff.append(h)
            idx_buff.append(idx)
        for i in range(D//2-1, D//2+1):
            h = F.relu(self.bn[i](self.conv[i+1](h)))
        for i in range(D//2+1, D):
            j = i - (D//2 + 1) + 1
            h = F.max_unpool2d(F.relu(self.bn[i](self.conv[i+1]((h+h_buff[-j])/np.sqrt(2)))), 
                               idx_buff[-j], kernel_size=(2,2), output_size=shape_buff[-j])
        y = self.conv[D+1](h) + x
        return y
```

### `UDnCNN` 炼丹


```python
lr = 1e-3
net = UDnCNN(6).to(device)
adam = torch.optim.Adam(net.parameters(), lr=lr)
stats_manager = DenoisingStatsManager()
exp2 = nt.Experiment(net, train_set, test_set, adam, stats_manager, batch_size=4, 
               output_dir="./checkpoints/denoising2", perform_validation_during_training=True)
```


```python
fig, axes = plt.subplots(ncols=2, nrows=2, figsize=(9, 7))
exp2.run(num_epochs=200, plot=lambda exp: plot(exp, fig=fig, axes=axes,
                                                noisy=test_set[0][0]))
```

    Start/Continue training from epoch 200
    Finish training for 200 epochs
    


    
![png](1_files/1_43_1.png)
    


### `UDnCNN` 网络参数


```python
for name, param in exp2.net.named_parameters():
    print(name, param.size(), param.requires_grad)
```

    conv.0.weight torch.Size([64, 3, 3, 3]) True
    conv.0.bias torch.Size([64]) True
    conv.1.weight torch.Size([64, 64, 3, 3]) True
    conv.1.bias torch.Size([64]) True
    conv.2.weight torch.Size([64, 64, 3, 3]) True
    conv.2.bias torch.Size([64]) True
    conv.3.weight torch.Size([64, 64, 3, 3]) True
    conv.3.bias torch.Size([64]) True
    conv.4.weight torch.Size([64, 64, 3, 3]) True
    conv.4.bias torch.Size([64]) True
    conv.5.weight torch.Size([64, 64, 3, 3]) True
    conv.5.bias torch.Size([64]) True
    conv.6.weight torch.Size([64, 64, 3, 3]) True
    conv.6.bias torch.Size([64]) True
    conv.7.weight torch.Size([3, 64, 3, 3]) True
    conv.7.bias torch.Size([3]) True
    bn.0.weight torch.Size([64]) True
    bn.0.bias torch.Size([64]) True
    bn.1.weight torch.Size([64]) True
    bn.1.bias torch.Size([64]) True
    bn.2.weight torch.Size([64]) True
    bn.2.bias torch.Size([64]) True
    bn.3.weight torch.Size([64]) True
    bn.3.bias torch.Size([64]) True
    bn.4.weight torch.Size([64]) True
    bn.4.bias torch.Size([64]) True
    bn.5.weight torch.Size([64]) True
    bn.5.bias torch.Size([64]) True
    

池化不改变参数个数，还是 `3456 + 36864 x D`.

感受野 (Receptive Field) 计算：

$R_D=(1+\sum_{i=1}^{D/2}2^i+2\times 2^{D/2}+\sum_{i=1}^{D/2-1}2^i+2)^2$.

`D=6` 为例 $R_6(1+(2+4+8)+(2\times 8)+(4+2)+2)^2=39^2$.

从 PSNR 看，加了 U-Net 更烂了... 池化会丢失价值特征信息，但图上看起来更“好看”了...

### 比比 `DnCNN` 和 `UDnCNN`


```python
# DnCNN
exp1.evaluate()
```




    {'PSNR': tensor(29.0716), 'loss': 0.0051106692105531695}




```python
# UDnCNN
exp2.evaluate()
```




    {'PSNR': tensor(28.4064), 'loss': 0.0059140139166265725}




```python
img = []
titles = ['clean', 'noise', 'DnCNN','UDnCNN']

x, clean = test_set[0]
x = x.unsqueeze(0).to(device)
img.append(clean)
img.append(x[0])

model = exp1.net.to(device)
model.eval()
with torch.no_grad():
    y = model.forward(x)
img.append(y[0])

model = exp2.net.to(device)
model.eval()
with torch.no_grad():
    y = model.forward(x)
img.append(y[0])
    
fig, axes = plt.subplots(ncols=4, figsize=(20,10), sharex='all', sharey='all')
for i in range(len(img)):
    myimshow(img[i], ax=axes[i])
    axes[i].set_title(f'{titles[i]}')
```


    
![png](1_files/1_50_0.png)
    


## 5. DUDnCNN
U-net like CNNs with dilated convolutions

空洞卷积(dilated convolution)代替池化来增大感受野(Receptive Field)

然而 pytorch 空洞卷积跑的贼慢，原理上看应该和普通卷积差不多快，这里有个优化的问题...

空洞卷积之前
`torch.backends.cudnn.benchmark=True` 之后改回 `torch.backends.cudnn.benchmark=False` 可以提速，详见 [https://github.com/pytorch/pytorch/issues/15054](https://github.com/pytorch/pytorch/issues/15054).


```python
class DUDnCNN(NNRegressor):

    def __init__(self, D, C=64):
        super(DUDnCNN, self).__init__()
        self.D = D
        
        # compute k(max_pool) and l(max_unpool)
        k = [0]
        k.extend([i for i in range(D//2)])
        k.extend([k[-1] for _ in range(D//2, D+1)])
        l = [0 for _ in range(D//2+1)]
        l.extend([i for i in range(D+1-(D//2+1))])
        l.append(l[-1])
        
        # 空洞卷积
        holes = [2**(kl[0]-kl[1])-1 for kl in zip(k,l)]
        dilations = [i+1 for i in holes]
        
        # 卷积层
        self.conv = nn.ModuleList()
        self.conv.append(nn.Conv2d(3, C, 3, padding=dilations[0], dilation=dilations[0]))
        self.conv.extend([nn.Conv2d(C, C, 3, padding=dilations[i+1], dilation=dilations[i+1]) for i in range(D)])
        self.conv.append(nn.Conv2d(C, 3, 3, padding=dilations[-1], dilation=dilations[-1]))
        # Kaiming正态分布初始化，又叫啥He('s) initialization
        for i in range(len(self.conv[:-1])):
            nn.init.kaiming_normal_(self.conv[i].weight.data, nonlinearity='relu')
        
        # batch norm
        self.bn = nn.ModuleList()
        self.bn.extend([nn.BatchNorm2d(C, C) for _ in range(D)])
        # Batch norm layer 初始化权值
        for i in range(D):
            nn.init.constant_(self.bn[i].weight.data, 1.25 * np.sqrt(C))

    def forward(self, x):
        D = self.D
        h = F.relu(self.conv[0](x))
        h_buff = []

        for i in range(D//2 - 1):
            torch.backends.cudnn.benchmark = True
            h = self.conv[i+1](h)
            torch.backends.cudnn.benchmark = False
            h = F.relu(self.bn[i](h))
            h_buff.append(h)
            
        for i in range(D//2 - 1, D//2 + 1):
            torch.backends.cudnn.benchmark = True
            h = self.conv[i+1](h)
            torch.backends.cudnn.benchmark = False
            h = F.relu(self.bn[i](h))
            
        for i in range(D//2 + 1, D):
            j = i - (D//2 + 1) + 1
            torch.backends.cudnn.benchmark = True
            h = self.conv[i+1]((h + h_buff[-j]) / np.sqrt(2))
            torch.backends.cudnn.benchmark = False
            h = F.relu(self.bn[i](h))
            
        y = self.conv[D+1](h) + x
        return y
```

### `DUDnCNN` 炼丹


```python
lr = 1e-3
net = DUDnCNN(6).to(device)
adam = torch.optim.Adam(net.parameters(), lr=lr)
stats_manager = DenoisingStatsManager()
exp3 = nt.Experiment(net, train_set, test_set, adam, stats_manager, batch_size=4, 
               output_dir="./checkpoints/denoising3", perform_validation_during_training=True)
```


```python
exp3
```




    Net(DUDnCNN(
      (mse): MSELoss()
      (conv): ModuleList(
        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))
        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))
        (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
        (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (bn): ModuleList(
        (0): BatchNorm2d(64, eps=64, momentum=0.1, affine=True, track_running_stats=True)
        (1): BatchNorm2d(64, eps=64, momentum=0.1, affine=True, track_running_stats=True)
        (2): BatchNorm2d(64, eps=64, momentum=0.1, affine=True, track_running_stats=True)
        (3): BatchNorm2d(64, eps=64, momentum=0.1, affine=True, track_running_stats=True)
        (4): BatchNorm2d(64, eps=64, momentum=0.1, affine=True, track_running_stats=True)
        (5): BatchNorm2d(64, eps=64, momentum=0.1, affine=True, track_running_stats=True)
      )
    ))
    TrainSet(NoisyBSDSDataset(mode=train, image_size=(180, 180), sigma=30))
    ValSet(NoisyBSDSDataset(mode=test, image_size=(320, 320), sigma=30))
    Optimizer(Adam (
    Parameter Group 0
        amsgrad: False
        betas: (0.9, 0.999)
        eps: 1e-08
        lr: 0.001
        weight_decay: 0
    ))
    StatsManager(DenoisingStatsManager)
    BatchSize(4)
    PerformValidationDuringTraining(True)




```python
fig, axes = plt.subplots(ncols=2, nrows=2, figsize=(9, 7))
exp3.run(num_epochs=200, plot=lambda exp: plot(exp, fig=fig, axes=axes,
                                                noisy=test_set[0][0]))
```

    Start/Continue training from epoch 11
    Epoch 12 (Time: 19.62s)
    Epoch 13 (Time: 19.43s)
    Epoch 14 (Time: 19.42s)
    Epoch 15 (Time: 19.43s)
    Epoch 16 (Time: 19.46s)
    Epoch 17 (Time: 19.45s)
    Epoch 18 (Time: 19.37s)
    Epoch 19 (Time: 19.34s)
    Epoch 20 (Time: 19.42s)
    Epoch 21 (Time: 19.40s)
    Epoch 22 (Time: 19.40s)
    Epoch 23 (Time: 19.43s)
    Epoch 24 (Time: 19.43s)
    Epoch 25 (Time: 19.42s)
    Epoch 26 (Time: 19.40s)
    Epoch 27 (Time: 19.44s)
    Epoch 28 (Time: 19.35s)
    Epoch 29 (Time: 19.09s)
    Epoch 30 (Time: 19.07s)
    Epoch 31 (Time: 19.05s)
    Epoch 32 (Time: 19.12s)
    Epoch 33 (Time: 19.09s)
    Epoch 34 (Time: 19.17s)
    Epoch 35 (Time: 19.02s)
    Epoch 36 (Time: 19.15s)
    Epoch 37 (Time: 19.12s)
    Epoch 38 (Time: 19.00s)
    Epoch 39 (Time: 18.99s)
    Epoch 40 (Time: 18.98s)
    Epoch 41 (Time: 18.97s)
    Epoch 42 (Time: 18.96s)
    Epoch 43 (Time: 18.93s)
    Epoch 44 (Time: 18.97s)
    Epoch 45 (Time: 18.93s)
    Epoch 46 (Time: 18.96s)
    Epoch 47 (Time: 18.90s)
    Epoch 48 (Time: 18.94s)
    Epoch 49 (Time: 18.93s)
    Epoch 50 (Time: 18.97s)
    Epoch 51 (Time: 18.95s)
    Epoch 52 (Time: 18.92s)
    Epoch 53 (Time: 18.98s)
    Epoch 54 (Time: 18.94s)
    Epoch 55 (Time: 19.00s)
    Epoch 56 (Time: 18.92s)
    Epoch 57 (Time: 18.93s)
    Epoch 58 (Time: 19.00s)
    Epoch 59 (Time: 18.97s)
    Epoch 60 (Time: 18.96s)
    Epoch 61 (Time: 18.93s)
    Epoch 62 (Time: 18.94s)
    Epoch 63 (Time: 18.89s)
    Epoch 64 (Time: 18.90s)
    Epoch 65 (Time: 18.95s)
    Epoch 66 (Time: 18.89s)
    Epoch 67 (Time: 18.90s)
    Epoch 68 (Time: 18.91s)
    Epoch 69 (Time: 18.89s)
    Epoch 70 (Time: 18.96s)
    Epoch 71 (Time: 18.91s)
    Epoch 72 (Time: 18.96s)
    Epoch 73 (Time: 18.89s)
    Epoch 74 (Time: 18.93s)
    Epoch 75 (Time: 18.88s)
    Epoch 76 (Time: 18.90s)
    Epoch 77 (Time: 18.90s)
    Epoch 78 (Time: 18.90s)
    Epoch 79 (Time: 18.92s)
    Epoch 80 (Time: 18.94s)
    Epoch 81 (Time: 18.94s)
    Epoch 82 (Time: 18.97s)
    Epoch 83 (Time: 18.91s)
    Epoch 84 (Time: 18.94s)
    Epoch 85 (Time: 18.89s)
    Epoch 86 (Time: 18.92s)
    Epoch 87 (Time: 18.96s)
    Epoch 88 (Time: 18.95s)
    Epoch 89 (Time: 18.92s)
    Epoch 90 (Time: 18.92s)
    Epoch 91 (Time: 18.94s)
    Epoch 92 (Time: 18.89s)
    Epoch 93 (Time: 18.92s)
    Epoch 94 (Time: 18.87s)
    Epoch 95 (Time: 18.92s)
    Epoch 96 (Time: 18.90s)
    Epoch 97 (Time: 18.87s)
    Epoch 98 (Time: 19.00s)
    Epoch 99 (Time: 18.93s)
    Epoch 100 (Time: 18.98s)
    Epoch 101 (Time: 18.93s)
    Epoch 102 (Time: 18.95s)
    Epoch 103 (Time: 18.93s)
    Epoch 104 (Time: 18.94s)
    Epoch 105 (Time: 18.94s)
    Epoch 106 (Time: 18.97s)
    Epoch 107 (Time: 18.94s)
    Epoch 108 (Time: 18.99s)
    Epoch 109 (Time: 18.94s)
    Epoch 110 (Time: 18.98s)
    Epoch 111 (Time: 18.90s)
    Epoch 112 (Time: 18.95s)
    Epoch 113 (Time: 18.93s)
    Epoch 114 (Time: 18.96s)
    Epoch 115 (Time: 18.94s)
    Epoch 116 (Time: 18.95s)
    Epoch 117 (Time: 18.92s)
    Epoch 118 (Time: 19.01s)
    Epoch 119 (Time: 18.89s)
    Epoch 120 (Time: 18.91s)
    Epoch 121 (Time: 18.90s)
    Epoch 122 (Time: 19.00s)
    Epoch 123 (Time: 18.95s)
    Epoch 124 (Time: 18.96s)
    Epoch 125 (Time: 18.96s)
    Epoch 126 (Time: 18.91s)
    Epoch 127 (Time: 18.90s)
    Epoch 128 (Time: 18.95s)
    Epoch 129 (Time: 18.92s)
    Epoch 130 (Time: 18.97s)
    Epoch 131 (Time: 18.94s)
    Epoch 132 (Time: 18.94s)
    Epoch 133 (Time: 18.94s)
    Epoch 134 (Time: 18.99s)
    Epoch 135 (Time: 18.90s)
    Epoch 136 (Time: 18.98s)
    Epoch 137 (Time: 18.89s)
    Epoch 138 (Time: 18.96s)
    Epoch 139 (Time: 18.89s)
    Epoch 140 (Time: 18.95s)
    Epoch 141 (Time: 18.93s)
    Epoch 142 (Time: 18.90s)
    Epoch 143 (Time: 18.94s)
    Epoch 144 (Time: 18.92s)
    Epoch 145 (Time: 18.94s)
    Epoch 146 (Time: 18.94s)
    Epoch 147 (Time: 18.92s)
    Epoch 148 (Time: 18.96s)
    Epoch 149 (Time: 18.96s)
    Epoch 150 (Time: 18.94s)
    Epoch 151 (Time: 18.89s)
    Epoch 152 (Time: 18.91s)
    Epoch 153 (Time: 18.94s)
    Epoch 154 (Time: 18.90s)
    Epoch 155 (Time: 18.94s)
    Epoch 156 (Time: 18.95s)
    Epoch 157 (Time: 18.97s)
    Epoch 158 (Time: 19.00s)
    Epoch 159 (Time: 18.95s)
    Epoch 160 (Time: 19.01s)
    Epoch 161 (Time: 18.94s)
    Epoch 162 (Time: 19.02s)
    Epoch 163 (Time: 18.92s)
    Epoch 164 (Time: 18.97s)
    Epoch 165 (Time: 18.94s)
    Epoch 166 (Time: 18.92s)
    Epoch 167 (Time: 18.93s)
    Epoch 168 (Time: 18.90s)
    Epoch 169 (Time: 18.95s)
    Epoch 170 (Time: 18.92s)
    Epoch 171 (Time: 18.92s)
    Epoch 172 (Time: 19.02s)
    Epoch 173 (Time: 18.96s)
    Epoch 174 (Time: 19.02s)
    Epoch 175 (Time: 19.00s)
    Epoch 176 (Time: 18.97s)
    Epoch 177 (Time: 19.01s)
    Epoch 178 (Time: 18.99s)
    Epoch 179 (Time: 18.98s)
    Epoch 180 (Time: 18.98s)
    Epoch 181 (Time: 19.01s)
    Epoch 182 (Time: 18.95s)
    Epoch 183 (Time: 18.95s)
    Epoch 184 (Time: 19.00s)
    Epoch 185 (Time: 18.92s)
    Epoch 186 (Time: 19.00s)
    Epoch 187 (Time: 18.92s)
    Epoch 188 (Time: 18.98s)
    Epoch 189 (Time: 18.97s)
    Epoch 190 (Time: 18.99s)
    Epoch 191 (Time: 18.98s)
    Epoch 192 (Time: 18.93s)
    Epoch 193 (Time: 18.99s)
    Epoch 194 (Time: 19.01s)
    Epoch 195 (Time: 18.94s)
    Epoch 196 (Time: 18.95s)
    Epoch 197 (Time: 18.90s)
    Epoch 198 (Time: 18.95s)
    Epoch 199 (Time: 18.91s)
    Epoch 200 (Time: 18.94s)
    Finish training for 200 epochs
    


    
![png](1_files/1_58_1.png)
    


### 比较 `DnCNN` `UDnCNN` `DUDnCNN`


```python
# DnCNN
exp1.evaluate()
```




    {'PSNR': tensor(29.0708), 'loss': 0.005108698001131415}




```python
# UDnCNN
exp2.evaluate()
```




    {'PSNR': tensor(28.4299), 'loss': 0.005884343096986413}




```python
# DUDnCNN
exp3.evaluate()
```




    {'PSNR': tensor(29.3069), 'loss': 0.004860227378085256}




```python
num = 3
img = []
nets = [exp1.net, exp2.net, exp3.net]
titles = ['noise','DnCNN', 'UDnCNN', 'DUDnCNN']

fig, axes = plt.subplots(nrows=num, ncols=4, figsize=(20,15), sharex='all', sharey='all')

for i in range(num):
    myimshow(test_set[7*i+7][0], ax=axes[i][0])
    x, _ = test_set[7*i+7]
    x = x.unsqueeze(0).to(device)
    img.append(x)

for i in range(num):
    for j in range(len(nets)):
        
        model = nets[j].to(device)
        model.eval()
        with torch.no_grad():
            y = model.forward(img[i])
        myimshow(y[0], ax=axes[i][j+1])
for i in range(num):
    for j in range(len(titles)):
        axes[i][j].set_title(f'{titles[j]}')
```


    
![png](1_files/1_63_0.png)
    


### `DUDnCNN` 网络参数


```python
exp3.net
```




    DUDnCNN(
      (mse): MSELoss()
      (conv): ModuleList(
        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))
        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))
        (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
        (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (bn): ModuleList(
        (0): BatchNorm2d(64, eps=64, momentum=0.1, affine=True, track_running_stats=True)
        (1): BatchNorm2d(64, eps=64, momentum=0.1, affine=True, track_running_stats=True)
        (2): BatchNorm2d(64, eps=64, momentum=0.1, affine=True, track_running_stats=True)
        (3): BatchNorm2d(64, eps=64, momentum=0.1, affine=True, track_running_stats=True)
        (4): BatchNorm2d(64, eps=64, momentum=0.1, affine=True, track_running_stats=True)
        (5): BatchNorm2d(64, eps=64, momentum=0.1, affine=True, track_running_stats=True)
      )
    )




```python
for name, param in exp3.net.named_parameters():
    print(name, param.size(), param.requires_grad)
```

    conv.0.weight torch.Size([64, 3, 3, 3]) True
    conv.0.bias torch.Size([64]) True
    conv.1.weight torch.Size([64, 64, 3, 3]) True
    conv.1.bias torch.Size([64]) True
    conv.2.weight torch.Size([64, 64, 3, 3]) True
    conv.2.bias torch.Size([64]) True
    conv.3.weight torch.Size([64, 64, 3, 3]) True
    conv.3.bias torch.Size([64]) True
    conv.4.weight torch.Size([64, 64, 3, 3]) True
    conv.4.bias torch.Size([64]) True
    conv.5.weight torch.Size([64, 64, 3, 3]) True
    conv.5.bias torch.Size([64]) True
    conv.6.weight torch.Size([64, 64, 3, 3]) True
    conv.6.bias torch.Size([64]) True
    conv.7.weight torch.Size([3, 64, 3, 3]) True
    conv.7.bias torch.Size([3]) True
    bn.0.weight torch.Size([64]) True
    bn.0.bias torch.Size([64]) True
    bn.1.weight torch.Size([64]) True
    bn.1.bias torch.Size([64]) True
    bn.2.weight torch.Size([64]) True
    bn.2.bias torch.Size([64]) True
    bn.3.weight torch.Size([64]) True
    bn.3.bias torch.Size([64]) True
    bn.4.weight torch.Size([64]) True
    bn.4.bias torch.Size([64]) True
    bn.5.weight torch.Size([64]) True
    bn.5.bias torch.Size([64]) True
    

参数个数还是不变 `3456 + 36864 x D`

感受野 (Receptive Field) 计算： 

$R_D=(1+2+\sum_{i=1}^{D/2}2^i\times 2^{i-1}+2^{D/2}\times 2^{D/2-1}+\sum_{i=1}^{D/2-1}2^i\times 2^{i-1}+2)^2$. 

$R_6=89^2$.
